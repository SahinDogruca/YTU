import json
import os
import shutil
from pathlib import Path
from collections import defaultdict
import hashlib
import random
import re
from sklearn.model_selection import train_test_split


class LabelMeToYOLO:
    def __init__(
        self,
        images_dir,
        json_dir,
        output_dir,
        train_ratio=0.7,
        val_ratio=0.15,
        test_ratio=0.15,
    ):
        self.images_dir = Path(images_dir)
        self.json_dir = Path(json_dir)
        self.output_dir = Path(output_dir)

        # Split oranlarÄ±
        self.train_ratio = train_ratio
        self.val_ratio = val_ratio
        self.test_ratio = test_ratio

        # YOLO klasÃ¶r yapÄ±sÄ±
        self.splits = ["train", "valid", "test"]
        for split in self.splits:
            (self.output_dir / split / "images").mkdir(parents=True, exist_ok=True)
            (self.output_dir / split / "labels").mkdir(parents=True, exist_ok=True)

        self.class_names = set()
        self.stats = {
            "total_images": 0,
            "total_jsons": 0,
            "matched": 0,
            "duplicate_images": 0,
            "duplicate_jsons": 0,
            "unmatched_images": 0,
            "unmatched_jsons": 0,
        }
        # Yeni isimleri tutmak iÃ§in eÅŸleÅŸtirme tablosu
        self.new_filename_map = {}

    def get_file_hash(self, filepath):
        """DosyanÄ±n hash'ini hesapla (kopya kontrolÃ¼ iÃ§in)"""
        hash_md5 = hashlib.md5()
        with open(filepath, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()

    def normalize_filename(self, filename):
        """Dosya adÄ±nÄ± normalize et (uzantÄ±sÄ±z) - LabelMe'deki ekleri temizlemek iÃ§in eski metot"""
        # UzantÄ±yÄ± kaldÄ±r
        name = Path(filename).stem
        # (1), (2) gibi ekleri kaldÄ±r
        if name.endswith(")") and "(" in name:
            base = name.rsplit("(", 1)[0]
            return base
        return name

    def normalize_filename_strict(self, filename):
        """
        Dosya adÄ±nÄ± sÄ±kÄ± kurallara gÃ¶re normalize et:
        1. TÃ¼rkÃ§e karakterleri Ä°ngilizce karÅŸÄ±lÄ±klarÄ±na Ã§evir.
        2. BoÅŸluklarÄ± ve Ã¶zel karakterleri alt Ã§izgiye Ã§evir.
        3. UzantÄ±yÄ± koru.
        """
        path = Path(filename)
        stem = path.stem
        suffix = path.suffix.lower()

        # 1. TÃ¼rkÃ§e karakterleri Ä°ngilizce karÅŸÄ±lÄ±klarÄ±na Ã§evir
        tr_to_en = {
            "Ã§": "c",
            "ÄŸ": "g",
            "Ä±": "i",
            "Ã¶": "o",
            "ÅŸ": "s",
            "Ã¼": "u",
            "Ã‡": "C",
            "Ä": "G",
            "Ä°": "I",
            "Ã–": "O",
            "Å": "S",
            "Ãœ": "U",
        }
        for tr, en in tr_to_en.items():
            stem = stem.replace(tr, en)

        # 2. Geriye kalan Ã¶zel karakterleri ve boÅŸluklarÄ± alt Ã§izgiye Ã§evir
        # Alfabetik, sayÄ±sal ve alt Ã§izgi dÄ±ÅŸÄ±ndaki her ÅŸeyi alt Ã§izgiye Ã§evir
        stem = re.sub(r"[^\w-]", "_", stem)

        # ArdÄ±ÅŸÄ±k alt Ã§izgileri tek bir alt Ã§izgiye indir
        stem = re.sub(r"__+", "_", stem)

        # BaÅŸlangÄ±Ã§ ve sondaki alt Ã§izgileri kaldÄ±r
        stem = stem.strip("_")

        # Tamamen boÅŸ kalÄ±rsa 'normalized_file' olarak adlandÄ±r
        if not stem:
            stem = "normalized_file"

        new_name = f"{stem}{suffix}"
        return new_name

    def find_image_files(self):
        """TÃ¼m resim dosyalarÄ±nÄ± bul, kopyalarÄ± tespit et ve isimleri normalize et"""
        image_extensions = {".jpg", ".jpeg", ".png", ".bmp"}
        images = {}
        image_hashes = defaultdict(list)

        original_to_new_path = {}

        for ext in image_extensions:
            for img_path in self.images_dir.glob(f"*{ext}"):
                # Orijinal dosya adÄ±nÄ± kaydet
                original_name = img_path.name

                # Yeni, normalize edilmiÅŸ adÄ± oluÅŸtur
                new_name = self.normalize_filename_strict(original_name)

                # Ã‡akÄ±ÅŸma kontrolÃ¼ (farklÄ± orijinal isimler aynÄ± yeni isme dÃ¶nÃ¼ÅŸmÃ¼ÅŸ olabilir)
                if new_name in images:
                    # Basit bir Ã§Ã¶zÃ¼m olarak, Ã§akÄ±ÅŸan ismin sonuna bir sayaÃ§ ekleyelim
                    i = 1
                    temp_new_name = new_name
                    while temp_new_name in images:
                        i += 1
                        temp_new_name = (
                            f"{Path(new_name).stem}_{i}{Path(new_name).suffix}"
                        )
                    new_name = temp_new_name

                # Bellekte orijinal Path yerine yeni adÄ± kullanÄ±yoruz
                images[new_name] = img_path
                self.new_filename_map[img_path] = (
                    new_name  # Orijinal Path -> Yeni Ä°sim eÅŸleÅŸmesi
                )

                img_hash = self.get_file_hash(img_path)
                image_hashes[img_hash].append(new_name)

        # KopyalarÄ± tespit et (Yeni isimler Ã¼zerinden)
        for hash_val, file_list in image_hashes.items():
            if len(file_list) > 1:
                self.stats["duplicate_images"] += len(file_list) - 1
                print(f"âš ï¸  Kopya resimler bulundu: {file_list}")

        self.stats["total_images"] = len(images)
        return images

    def find_json_files(self):
        """TÃ¼m JSON dosyalarÄ±nÄ± bul ve kopyalarÄ± tespit et"""
        jsons = {}
        json_hashes = defaultdict(list)

        for json_path in self.json_dir.glob("*.json"):
            jsons[json_path.name] = json_path
            json_hash = self.get_file_hash(json_path)
            json_hashes[json_hash].append(json_path.name)

        # KopyalarÄ± tespit et
        for hash_val, file_list in json_hashes.items():
            if len(file_list) > 1:
                self.stats["duplicate_jsons"] += len(file_list) - 1
                print(f"âš ï¸  Kopya JSON'lar bulundu: {file_list}")

        self.stats["total_jsons"] = len(jsons)
        return jsons

    def match_files(self, images, jsons):
        """Resim ve JSON dosyalarÄ±nÄ± eÅŸleÅŸtir (ArtÄ±k 'images' normalize edilmiÅŸ isimleri kullanÄ±yor)"""
        matches = []

        # images sÃ¶zlÃ¼ÄŸÃ¼: {yeni_ad: orijinal_path}
        # self.new_filename_map sÃ¶zlÃ¼ÄŸÃ¼: {orijinal_path: yeni_ad}

        for json_name, json_path in jsons.items():
            try:
                with open(json_path, "r", encoding="utf-8") as f:
                    data = json.load(f)

                    # 1. JSON'daki imagePath'i kontrol ederek eÅŸleÅŸtir (orijinal isim Ã¼zerinden)
                    image_path_in_json = data.get("imagePath", "")
                    image_name_in_json = Path(image_path_in_json).name

                    # Orijinal Resim dosya adÄ±na karÅŸÄ±lÄ±k gelen yeni ismi bulmaya Ã§alÄ±ÅŸ
                    matched_new_name = None
                    matched_original_path = None

                    # Orijinal resim adÄ±na gÃ¶re eÅŸleÅŸen orijinal yolu bul
                    original_image_path = None

                    # find_image_files'da orijinal adÄ± kullanmadÄ±ÄŸÄ±mÄ±z iÃ§in, Ã¶nce orijinal adÄ± alÄ±p
                    # onun Path'ini bulup, Path'ten yeni adÄ±na gitmek daha mantÄ±klÄ±.

                    # Hata: images sÃ¶zlÃ¼ÄŸÃ¼nde orijinal isimler yok. TÃ¼m resim Path'lerini taramalÄ±yÄ±z.
                    all_original_image_paths = [
                        p
                        for p in self.new_filename_map.keys()
                        if p.name == image_name_in_json
                    ]

                    if all_original_image_paths:
                        # EÄŸer bir resim bulunursa (genellikle 1 tane olmalÄ±)
                        original_image_path = all_original_image_paths[0]
                        matched_new_name = self.new_filename_map.get(
                            original_image_path
                        )
                        matched_original_path = original_image_path

                    if matched_new_name and matched_new_name in images:
                        # EÅŸleÅŸme bulundu
                        matches.append(
                            (matched_original_path, json_path, matched_new_name)
                        )  # (orijinal_resim_path, json_path, yeni_resim_adÄ±)
                        continue

                    # 2. Alternatif: JSON dosya adÄ±na gÃ¶re eÅŸleÅŸtir (normalize edilmiÅŸ isimler Ã¼zerinden)
                    json_base_original = self.normalize_filename(
                        json_name
                    )  # LabelMe'nin (1) (2) eklerini temizle

                    for new_img_name, original_img_path in images.items():
                        # Orijinal Resim dosya adÄ±nÄ±n (uzantÄ±sÄ±z) normalize edilmiÅŸ halini al (eski metotla)
                        img_base_original = self.normalize_filename(
                            original_img_path.name
                        )

                        if json_base_original == img_base_original:
                            # EÅŸleÅŸme bulundu
                            matches.append(
                                (original_img_path, json_path, new_img_name)
                            )  # (orijinal_resim_path, json_path, yeni_resim_adÄ±)
                            break
            except Exception as e:
                print(f"âŒ JSON okuma hatasÄ± ({json_name}): {e}")

        self.stats["matched"] = len(matches)
        return matches

    def polygon_to_yolo(self, points, img_width, img_height):
        """Polygon koordinatlarÄ±nÄ± YOLO formatÄ±na Ã§evir"""
        # Normalize et ve dÃ¼zleÅŸtir
        normalized = []
        for x, y in points:
            normalized.append(x / img_width)
            normalized.append(y / img_height)
        return normalized

    def get_json_classes(self, json_path):
        """JSON dosyasÄ±ndaki tÃ¼m sÄ±nÄ±flarÄ± al"""
        try:
            with open(json_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            classes = set()
            for shape in data["shapes"]:
                label = shape["label"].lower().strip()
                classes.add(label)
            return classes
        except:
            return set()

    def stratified_split(self, matches):
        """SÄ±nÄ±f dengesini koruyarak veriyi bÃ¶l"""
        print(f"\nğŸ“Š SÄ±nÄ±f dengeli split yapÄ±lÄ±yor...")

        # Her Ã¶rnek iÃ§in sÄ±nÄ±f bilgisini topla
        sample_classes = []
        for original_img_path, json_path, new_img_name in matches:
            classes = self.get_json_classes(json_path)
            # Multi-label iÃ§in en yaygÄ±n sÄ±nÄ±fÄ± kullan veya birleÅŸtir
            class_label = "_".join(sorted(classes)) if classes else "unknown"
            sample_classes.append(class_label)

        # SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶ster
        class_counts = defaultdict(int)
        for cls in sample_classes:
            class_counts[cls] += 1

        print(f"\n   SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±:")
        for cls, count in sorted(class_counts.items()):
            print(f"   - {cls}: {count} Ã¶rnek")

        # Stratified split (sklearn kullanarak)
        indices = list(range(len(matches)))

        # Ä°lk olarak train ve temp (val+test) olarak ayÄ±r
        train_indices, temp_indices = train_test_split(
            indices,
            test_size=(self.val_ratio + self.test_ratio),
            random_state=42,
            stratify=sample_classes,
        )

        # Temp'i val ve test olarak ayÄ±r
        temp_classes = [sample_classes[i] for i in temp_indices]
        val_size = self.val_ratio / (self.val_ratio + self.test_ratio)

        val_indices, test_indices = train_test_split(
            temp_indices,
            test_size=(1 - val_size),
            random_state=42,
            stratify=temp_classes,
        )

        # Ä°ndekslere gÃ¶re matches'i ayÄ±r
        train_matches = [matches[i] for i in train_indices]
        val_matches = [matches[i] for i in val_indices]
        test_matches = [matches[i] for i in test_indices]

        print(f"\n   âœ… Split SonuÃ§larÄ±:")
        print(
            f"   - Train: {len(train_matches)} Ã¶rnek ({len(train_matches)/len(matches)*100:.1f}%)"
        )
        print(
            f"   - Valid: {len(val_matches)} Ã¶rnek ({len(val_matches)/len(matches)*100:.1f}%)"
        )
        print(
            f"   - Test: {len(test_matches)} Ã¶rnek ({len(test_matches)/len(matches)*100:.1f}%)"
        )

        return {"train": train_matches, "valid": val_matches, "test": test_matches}

    def convert_json_to_yolo(self, json_path, output_path, class_to_id, new_img_name):
        """Tek bir JSON dosyasÄ±nÄ± YOLO formatÄ±na Ã§evir ve imagePath'i gÃ¼ncelle"""
        try:
            with open(json_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            # --- GÃ¼ncelleme BaÅŸlangÄ±cÄ± ---
            # JSON iÃ§indeki imagePath'i yeni, normalize edilmiÅŸ dosya adÄ± ile gÃ¼ncelle
            data["imagePath"] = new_img_name

            # JSON dosyasÄ±nÄ± *aynÄ± yere* gÃ¼ncellenmiÅŸ haliyle kaydet (opsiyonel ama tutarlÄ±lÄ±k iÃ§in iyi)
            # Not: Bu, orijinal JSON dosyasÄ±nÄ± kalÄ±cÄ± olarak deÄŸiÅŸtirir. Geriye dÃ¶nÃ¼k uyumluluk iÃ§in dikkatli olunmalÄ±dÄ±r.
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=4)
            # --- GÃ¼ncelleme Sonu ---

            img_width = data["imageWidth"]
            img_height = data["imageHeight"]

            yolo_annotations = []

            for shape in data["shapes"]:
                label = shape["label"].lower().strip()  # Lowercase + boÅŸluklarÄ± temizle
                points = shape["points"]

                # SÄ±nÄ±f ID'si
                if label not in class_to_id:
                    class_to_id[label] = len(class_to_id)
                class_id = class_to_id[label]

                # YOLO formatÄ±na Ã§evir (Sadece Polygon destekliyoruz, LabelMe'nin Bounding Box'u da aslÄ±nda 2 noktalÄ± bir Polygon'dur)
                yolo_coords = self.polygon_to_yolo(points, img_width, img_height)

                # YOLO satÄ±rÄ±: <class_id> <x1> <y1> <x2> <y2> ... <xn> <yn>
                line = f"{class_id} " + " ".join(
                    [f"{coord:.6f}" for coord in yolo_coords]
                )
                yolo_annotations.append(line)

            # YOLO dosyasÄ±na yaz
            with open(output_path, "w") as f:
                f.write("\n".join(yolo_annotations))

            return True
        except Exception as e:
            print(f"âŒ DÃ¶nÃ¼ÅŸtÃ¼rme/JSON GÃ¼ncelleme hatasÄ± ({json_path.name}): {e}")
            return False

    def create_yaml(self, class_to_id):
        """YOLO iÃ§in data.yaml dosyasÄ± oluÅŸtur"""
        yaml_content = f"""# YOLO Dataset Configuration
path: {self.output_dir.absolute()}
train: train/images
val: valid/images
test: test/images

# Classes
nc: {len(class_to_id)}
names: {list(class_to_id.keys())}
"""
        yaml_path = self.output_dir / "data.yaml"
        with open(yaml_path, "w", encoding="utf-8") as f:
            f.write(yaml_content)
        print(f"âœ… data.yaml oluÅŸturuldu: {yaml_path}")

    def convert(self):
        """Ana dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemi"""
        print("ğŸ” Dosyalar taranÄ±yor...")

        # DosyalarÄ± bul (Resim dosyalarÄ± bu aÅŸamada normalize edilmiÅŸ yeni isimlere eÅŸlenir)
        images = self.find_image_files()  # {yeni_ad: orijinal_path}
        jsons = self.find_json_files()

        print(f"\nğŸ“Š Ä°statistikler:")
        print(f"   Toplam resim: {self.stats['total_images']}")
        print(f"   Toplam JSON: {self.stats['total_jsons']}")
        print(f"   Kopya resim: {self.stats['duplicate_images']}")
        print(f"   Kopya JSON: {self.stats['duplicate_jsons']}")

        # EÅŸleÅŸtir
        print(f"\nğŸ”— Dosyalar eÅŸleÅŸtiriliyor...")
        # matches: (orijinal_resim_path, json_path, yeni_resim_adÄ±)
        matches = self.match_files(images, jsons)

        print(f"   âœ… EÅŸleÅŸen Ã§ift: {len(matches)}")
        print(f"   âš ï¸  EÅŸleÅŸmeyen resim: {self.stats['total_images'] - len(matches)}")
        print(f"   âš ï¸  EÅŸleÅŸmeyen JSON: {self.stats['total_jsons'] - len(matches)}")

        if len(matches) == 0:
            print("âŒ HiÃ§ eÅŸleÅŸme bulunamadÄ±!")
            return

        # Stratified split yap
        split_matches = self.stratified_split(matches)

        # DÃ¶nÃ¼ÅŸtÃ¼r ve kaydet
        print(f"\nğŸ”„ YOLO formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
        class_to_id = {}

        for split_name, split_data in split_matches.items():
            print(f"\n   ğŸ“ {split_name.upper()} seti iÅŸleniyor...")
            success_count = 0

            # split_data: (orijinal_img_path, json_path, new_img_name)
            for original_img_path, json_path, new_img_name in split_data:
                # Resmi yeni, normalize edilmiÅŸ adÄ±yla kopyala
                output_img = self.output_dir / split_name / "images" / new_img_name
                shutil.copy2(
                    original_img_path, output_img
                )  # Orijinal yoldan oku, yeni yola yaz

                # JSON'u YOLO formatÄ±na Ã§evir
                # Label dosya adÄ± (uzantÄ±sÄ±z) resim dosya adÄ±yla (uzantÄ±sÄ±z) aynÄ± olmalÄ±
                output_label = (
                    self.output_dir
                    / split_name
                    / "labels"
                    / f"{Path(new_img_name).stem}.txt"
                )

                # Yeni resim adÄ±nÄ± JSON gÃ¼ncellemesi iÃ§in fonksiyona iletiyoruz
                if self.convert_json_to_yolo(
                    json_path, output_label, class_to_id, new_img_name
                ):
                    success_count += 1

            print(f"      âœ… BaÅŸarÄ±yla dÃ¶nÃ¼ÅŸtÃ¼rÃ¼len: {success_count}/{len(split_data)}")

        # Classes dosyasÄ± oluÅŸtur
        classes_path = self.output_dir / "classes.txt"
        with open(classes_path, "w", encoding="utf-8") as f:
            for class_name in sorted(class_to_id.keys()):
                f.write(f"{class_name}\n")
        print(f"\nâœ… classes.txt oluÅŸturuldu")

        # YAML dosyasÄ± oluÅŸtur
        self.create_yaml(class_to_id)

        # Final istatistikler
        print(f"\nâœ¨ DÃ¶nÃ¼ÅŸtÃ¼rme tamamlandÄ±!")
        print(f"   ğŸ“‚ Ã‡Ä±ktÄ± dizini: {self.output_dir}")
        print(f"   ğŸ·ï¸  SÄ±nÄ±f sayÄ±sÄ±: {len(class_to_id)}")
        print(f"   ğŸ“‹ SÄ±nÄ±flar: {list(class_to_id.keys())}")
        print(f"\n   ğŸ“Š Final Dataset:")
        print(f"   - train/images: {len(split_matches['train'])} resim")
        print(f"   - valid/images: {len(split_matches['valid'])} resim")
        print(f"   - test/images: {len(split_matches['test'])} resim")


# KullanÄ±m
if __name__ == "__main__":
    # Dizinleri belirt
    IMAGES_DIR = "./data/temp_v2/IMAGES"  # Resim klasÃ¶rÃ¼nÃ¼z
    JSON_DIR = "./data/temp_v2/JSON"  # JSON klasÃ¶rÃ¼nÃ¼z
    OUTPUT_DIR = "./data/data_v2"  # Ã‡Ä±ktÄ± klasÃ¶rÃ¼

    # DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼yÃ¼ baÅŸlat (70% train, 15% valid, 15% test)
    converter = LabelMeToYOLO(
        IMAGES_DIR,
        JSON_DIR,
        OUTPUT_DIR,
        train_ratio=0.7,
        val_ratio=0.15,
        test_ratio=0.15,
    )
    converter.convert()
